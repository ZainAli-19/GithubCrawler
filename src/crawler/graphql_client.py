import asyncio
import logging
import aiohttp
from datetime import datetime, timezone

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# GitHub GraphQL Client (Enhanced 403 Handling)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class GitHubGraphQLClient:
    """
    Optimized asynchronous client for GitHub GraphQL API.
    Includes robust handling for rate limits, abuse detection,
    and automatic backoff logic to avoid 403 slowdowns.
    """

    API_URL = "https://api.github.com/graphql"

    def __init__(self, token: str, session: aiohttp.ClientSession):
        if not token:
            raise ValueError("âŒ Missing GitHub API token.")
        self.token = token
        self.session = session

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # GraphQL query
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    QUERY = """
    query ($queryString: String!, $cursor: String) {
      rateLimit {
        limit
        cost
        remaining
        resetAt
      }
      search(query: $queryString, type: REPOSITORY, first: 100, after: $cursor) {
        pageInfo {
          endCursor
          hasNextPage
        }
        nodes {
          ... on Repository {
            id
            name
            owner { login }
            stargazerCount
            forkCount
            createdAt
            updatedAt
            pushedAt
            url
            primaryLanguage { name }
          }
        }
      }
    }
    """

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Fetch repositories (resilient retry + backoff)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    async def fetch_repos(self, query_string: str, cursor: str = None):
        """
        Fetch one batch of repositories.
        Handles:
          - Full rate-limit exhaustion
          - Secondary rate-limit (abuse detection)
          - Network and transient GraphQL errors
        """
        for attempt in range(10):
            try:
                async with self.session.post(
                    self.API_URL,
                    headers={
                        "Authorization": f"Bearer {self.token}",
                        "Accept": "application/vnd.github+json",
                        "X-Github-Api-Version": "2022-11-28",
                    },
                    json={
                        "query": self.QUERY,
                        "variables": {"queryString": query_string, "cursor": cursor},
                    },
                ) as resp:

                    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                    # Handle rate-limit and throttling responses
                    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                    if resp.status == 403:
                        text = await resp.text()

                        # ğŸ§  Detect "secondary rate limit" (abuse throttle)
                        if "secondary rate limit" in text.lower() or "abuse" in text.lower():
                            logging.warning("ğŸš¦ Secondary rate limit triggered â€” backing off 60s...")
                            await asyncio.sleep(60)
                            continue

                        # Attempt to parse JSON to check true rate-limit exhaustion
                        try:
                            data = await resp.json()
                        except Exception:
                            data = {}

                        rl = data.get("data", {}).get("rateLimit", {}) if data.get("data") else {}
                        remaining = rl.get("remaining")
                        reset_at = rl.get("resetAt")

                        if remaining == 0 and reset_at:
                            reset_dt = datetime.strptime(reset_at, "%Y-%m-%dT%H:%M:%SZ").replace(
                                tzinfo=timezone.utc
                            )
                            wait_sec = max((reset_dt - datetime.now(timezone.utc)).total_seconds(), 0)
                            logging.warning(
                                f"ğŸ•’ True rate limit reached â€” waiting {wait_sec/60:.1f} minutes until reset..."
                            )
                            await asyncio.sleep(wait_sec + 5)
                            continue

                        # Generic 403 with no details â†’ short backoff
                        logging.warning("âš ï¸ Generic 403 error â€” sleeping 20s and retrying...")
                        await asyncio.sleep(20)
                        continue

                    elif resp.status >= 500:
                        logging.warning(f"âš ï¸ GitHub server error ({resp.status}) â€” retrying in 5s...")
                        await asyncio.sleep(5)
                        continue

                    elif resp.status != 200:
                        text = await resp.text()
                        logging.error(f"âŒ Unexpected HTTP {resp.status}: {text}")
                        await asyncio.sleep(5)
                        continue

                    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                    # Parse valid response
                    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                    data = await resp.json()

                    if "errors" in data:
                        logging.warning(f"âš ï¸ GraphQL errors: {data['errors']}")
                        await asyncio.sleep(5)
                        continue

                    rl = data.get("data", {}).get("rateLimit")
                    if rl:
                        reset_time = datetime.strptime(
                            rl["resetAt"], "%Y-%m-%dT%H:%M:%SZ"
                        ).replace(tzinfo=timezone.utc)
                        minutes_left = (reset_time - datetime.now(timezone.utc)).total_seconds() / 60
                        logging.info(
                            f"â± Rate limit: {rl['remaining']}/{rl['limit']} left "
                            f"(cost={rl['cost']}) â€” resets in {minutes_left:.1f} min"
                        )

                        # Back off slightly if near exhaustion
                        if rl["remaining"] < 50:
                            logging.warning("ğŸ›‘ Near rate-limit exhaustion â€” pausing 90s...")
                            await asyncio.sleep(90)

                    search_data = data.get("data", {}).get("search")
                    if not search_data:
                        logging.warning("âš ï¸ Empty or invalid search response â€” retrying in 3s...")
                        await asyncio.sleep(3)
                        continue

                    return {
                        "nodes": search_data.get("nodes", []),
                        "pageInfo": search_data.get("pageInfo", {}),
                    }

            except aiohttp.ClientError as e:
                logging.error(f"ğŸ’¥ Network error: {e}")
                await asyncio.sleep(5)
                continue

            except Exception as e:
                logging.exception(f"âš ï¸ Unexpected error: {e}")
                await asyncio.sleep(5)
                continue

        logging.error("âŒ Failed after multiple retries for query: %s", query_string)
        return None
