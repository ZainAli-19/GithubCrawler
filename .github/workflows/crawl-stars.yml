name: Crawl Stars

on:
  workflow_dispatch:        # ‚úÖ Manual trigger
  schedule:
    - cron: "0 0 * * *"     # ‚úÖ Run daily at midnight UTC

jobs:
  crawl:
    runs-on: ubuntu-latest
    timeout-minutes: 360    # Allow up to 6 hours for large crawls

    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: postgres
        ports:
          - 5432:5432
        options: >-
          --health-cmd "pg_isready -U postgres"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 10

    env:
      POSTGRES_HOST: 127.0.0.1
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: postgres
      GITHUB_TOKEN: ${{ github.token }}

    steps:
      # 1Ô∏è‚É£ Checkout repository
      - name: Checkout repository
        uses: actions/checkout@v4

      # 2Ô∏è‚É£ Set up Python
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      # 3Ô∏è‚É£ Install dependencies
      - name: Install dependencies
        run: |
          pip install -r src/requirements.txt

      # 4Ô∏è‚É£ Wait for PostgreSQL to be ready
      - name: Wait for PostgreSQL
        env:
          PGPASSWORD: postgres
        run: |
          echo "‚è≥ Waiting for PostgreSQL to be ready..."
          for i in {1..20}; do
            if pg_isready -h 127.0.0.1 -p 5432 -U postgres; then
              echo "‚úÖ PostgreSQL is ready!"
              break
            else
              echo "PostgreSQL not ready yet... waiting 3s"
              sleep 3
            fi
          done

      # 5Ô∏è‚É£ Recreate database schema (single migration file)
      - name: Setup database schema
        env:
          PGPASSWORD: postgres
        run: |
          echo "üì¶ Recreating database schema..."
          psql -h 127.0.0.1 -U postgres -d postgres -c "DROP TABLE IF EXISTS repositories, crawl_logs CASCADE;"
          psql -h 127.0.0.1 -U postgres -d postgres -f src/db/migrations/001_create_tables.sql
          echo "‚úÖ Database schema ready."

      # 6Ô∏è‚É£ Run Async Parallel Crawler
      - name: Run async parallel crawler
        working-directory: src
        env:
          POSTGRES_HOST: 127.0.0.1
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: postgres
          GITHUB_TOKEN: ${{ github.token }}
        run: |
          echo "üöÄ Running parallel async crawler (5 workers)..."
          python -m crawler.crawler_async
          echo "‚úÖ Parallel crawl completed successfully."

      # 7Ô∏è‚É£ Export Database Snapshot to CSV
      - name: Export repositories to CSV
        env:
          PGPASSWORD: postgres
        run: |
          mkdir -p data
          echo "üì§ Exporting repositories table..."
          psql -h 127.0.0.1 -U postgres -d postgres -c "\copy (SELECT * FROM repositories ORDER BY stars DESC) TO 'data/repos.csv' CSV HEADER"
          echo "‚úÖ Export complete."

      # 8Ô∏è‚É£ Verify total repositories crawled
      - name: Verify data count
        env:
          PGPASSWORD: postgres
        run: |
          echo "üìä Checking total repositories stored..."
          psql -h 127.0.0.1 -U postgres -d postgres -c "SELECT COUNT(*) AS total_repos FROM repositories;"

      # 9Ô∏è‚É£ Commit and Push Data Updates
      - name: Commit and push updated data
        run: |
          git config --global user.name "github-actions[bot]"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"
          mkdir -p data
          git add data/repos.csv
          if git diff --cached --quiet; then
            echo "üü° No new data to commit."
          else
            git commit -m "üìä Auto-update: GitHub repos crawl on $(date -u +"%Y-%m-%d %H:%M:%S UTC")"
            git push
            echo "‚úÖ Data committed and pushed."
          fi

      # üîü Upload Artifact for Manual Download
      - name: Upload artifact (repos.csv)
        uses: actions/upload-artifact@v4
        with:
          name: github-repos
          path: data/repos.csv
          if-no-files-found: error
